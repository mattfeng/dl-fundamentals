{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32473ff3-c3cb-4766-abec-9b405b143e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efcbb84c-51cc-4de0-bc66-ee63fce22095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wavenet import WaveNetBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677494a1-0fbd-424d-b8d2-56bf0ff4ff1d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c3d13",
   "metadata": {
    "deletable": false,
    "editable": false,
    "frozen": true
   },
   "source": [
    "## dilated causal convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3894305-88c1-4229-bc56-92d988913091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilatedCausalConv1d(nn.Conv1d):\n",
    "    def __init__(self, in_channels, out_channels, dilation):\n",
    "        super().__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=2,\n",
    "            stride=1,\n",
    "            padding=dilation,\n",
    "            dilation=dilation,\n",
    "            bias=False,\n",
    "            padding_mode=\"zeros\"\n",
    "        )\n",
    "        self.dilation_ = dilation\n",
    "\n",
    "    def forward(self, x):\n",
    "        ret = super().forward(x)\n",
    "        return ret[..., :-self.dilation_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9520b10-07f2-465e-b2bc-dc4538e31ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dccs = {2**i:DilatedCausalConv1d(2, 2, 2**i) for i in range(4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687a40dc-9ae9-44d1-a5c8-3d3348501a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: DilatedCausalConv1d(2, 2, kernel_size=(2,), stride=(1,), padding=(1,), bias=False),\n",
       " 2: DilatedCausalConv1d(2, 2, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,), bias=False),\n",
       " 4: DilatedCausalConv1d(2, 2, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,), bias=False),\n",
       " 8: DilatedCausalConv1d(2, 2, kernel_size=(2,), stride=(1,), padding=(8,), dilation=(8,), bias=False)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f30730-e000-4a56-9617-a73c85ae2f27",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "for dcc in dccs.values():\n",
    "    dcc.weight.data.fill_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a3549aa-2a9f-499a-b1ea-fb51a9f4f380",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7]])\n",
      "tensor([[[-0.3989, -0.0918,  0.7880, -1.1292,  0.5464, -0.4332, -0.9581,\n",
      "          -2.1084],\n",
      "         [ 0.2470,  2.2259, -0.6204, -1.3825, -1.3547, -1.1894, -1.1706,\n",
      "          -1.4953]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[-0.1519,  1.9822,  2.3017, -2.3442, -3.3201, -2.4310, -3.7513,\n",
      "          -5.7323],\n",
      "         [-0.1519,  1.9822,  2.3017, -2.3442, -3.3201, -2.4310, -3.7513,\n",
      "          -5.7323]]], grad_fn=<SliceBackward0>)\n",
      "tensor([[[ -0.3038,   3.9645,   4.2995,  -0.7240,  -2.0368,  -9.5505, -14.1428,\n",
      "          -16.3266],\n",
      "         [ -0.3038,   3.9645,   4.2995,  -0.7240,  -2.0368,  -9.5505, -14.1428,\n",
      "          -16.3266]]], grad_fn=<SliceBackward0>)\n",
      "tensor([[[ -0.6076,   7.9289,   8.5991,  -1.4480,  -4.6813, -11.1720, -19.6866,\n",
      "          -34.1013],\n",
      "         [ -0.6076,   7.9289,   8.5991,  -1.4480,  -4.6813, -11.1720, -19.6866,\n",
      "          -34.1013]]], grad_fn=<SliceBackward0>)\n",
      "tensor([[[ -1.2153,  15.8578,  17.1982,  -2.8960,  -9.3627, -22.3441, -39.3732,\n",
      "          -68.2026],\n",
      "         [ -1.2153,  15.8578,  17.1982,  -2.8960,  -9.3627, -22.3441, -39.3732,\n",
      "          -68.2026]]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "seq = torch.arange(8, dtype=torch.long).reshape(1, -1)\n",
    "print(seq)\n",
    "\n",
    "embed = nn.Embedding(255, 2)\n",
    "\n",
    "seq = embed(seq)\n",
    "seq = rearrange(seq, \"batch seq channels -> batch channels seq\") # PyTorch Conv1d required order \n",
    "                           \n",
    "print(seq)\n",
    "\n",
    "for dil in (1, 2, 4, 8):\n",
    "    dcc = dccs[dil]\n",
    "    seq = dcc(seq)\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f57eb97-cb5d-472f-adba-372c3ff8d94c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "```\n",
    "our perceptual system feeds raw tokens (photons, waves, etc.) into a Perceiver model that outputs embeddings, which are then processed by other models using a universal set of embeddings\n",
    "\n",
    "the current formulation of \"embeddings\" is holding ML back because it's arbitrary for every new model architecture...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713ede7-5245-48aa-a0b5-892fe1770f5b",
   "metadata": {},
   "source": [
    "## wavenet block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6e9bb83",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "wnb = WaveNetBlock(1, 6, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abeb1712-9bba-4963-81e2-f0af20e55ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6415,  2.0079,  1.2987, -1.6521],\n",
      "         [-0.4333,  2.0356,  0.5587, -0.2746],\n",
      "         [ 0.0465, -1.1569, -0.2227, -0.9221],\n",
      "         [-0.3786,  0.3795,  0.8372,  0.6274],\n",
      "         [ 2.1452, -0.3153,  1.5244, -0.4513],\n",
      "         [ 0.5395,  0.7476,  0.0573,  0.9140],\n",
      "         [ 1.0305, -0.6988,  0.3695, -0.6360],\n",
      "         [ 0.1316, -0.8818, -0.1656,  0.4459]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 8, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a00e686e-96d6-4ef7-a971-754bc66ca9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2766, -0.2638, -0.0616, -0.0880, -0.0358, -0.1975, -0.0095,\n",
       "           -0.1001],\n",
       "          [ 0.2595,  0.4514,  0.4089,  0.3159,  0.3149,  0.4715,  0.3673,\n",
       "            0.3817],\n",
       "          [-0.3067, -0.1060, -0.3404, -0.4422, -0.4741, -0.0669, -0.4493,\n",
       "           -0.2762],\n",
       "          [-0.4703, -0.5385, -0.4511, -0.4565, -0.4142, -0.4178, -0.4365,\n",
       "           -0.3758]]], grad_fn=<ConvolutionBackward0>),\n",
       " tensor([[[ 0.5628,  0.2582,  0.5419,  0.6263,  0.7145,  0.4346,  0.6398,\n",
       "            0.6511],\n",
       "          [-0.4450, -0.1115, -0.3777, -0.5143, -0.5695, -0.1573, -0.4977,\n",
       "           -0.4053]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e7598-879a-43c4-aa28-cf307d9624d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavenet",
   "language": "python",
   "name": "wavenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
