{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32473ff3-c3cb-4766-abec-9b405b143e1c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efcbb84c-51cc-4de0-bc66-ee63fce22095",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "from wavenet import WaveNetBlock, WaveNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677494a1-0fbd-424d-b8d2-56bf0ff4ff1d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c3d13",
   "metadata": {
    "deletable": false,
    "editable": false,
    "frozen": true
   },
   "source": [
    "## dilated causal convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3894305-88c1-4229-bc56-92d988913091",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "class DilatedCausalConv1d(nn.Conv1d):\n",
    "    def __init__(self, in_channels, out_channels, dilation):\n",
    "        super().__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=2,\n",
    "            stride=1,\n",
    "            padding=dilation,\n",
    "            dilation=dilation,\n",
    "            bias=False,\n",
    "            padding_mode=\"zeros\"\n",
    "        )\n",
    "        self.dilation_ = dilation\n",
    "\n",
    "    def forward(self, x):\n",
    "        ret = super().forward(x)\n",
    "        return ret[..., :-self.dilation_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9520b10-07f2-465e-b2bc-dc4538e31ed5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "dccs = {2**i:DilatedCausalConv1d(2, 2, 2**i) for i in range(4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687a40dc-9ae9-44d1-a5c8-3d3348501a6c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: DilatedCausalConv1d(2, 2, kernel_size=(2,), stride=(1,), padding=(1,), bias=False),\n",
       " 2: DilatedCausalConv1d(2, 2, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,), bias=False),\n",
       " 4: DilatedCausalConv1d(2, 2, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,), bias=False),\n",
       " 8: DilatedCausalConv1d(2, 2, kernel_size=(2,), stride=(1,), padding=(8,), dilation=(8,), bias=False)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f30730-e000-4a56-9617-a73c85ae2f27",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "for dcc in dccs.values():\n",
    "    dcc.weight.data.fill_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a3549aa-2a9f-499a-b1ea-fb51a9f4f380",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7]])\n",
      "tensor([[[-0.3989, -0.0918,  0.7880, -1.1292,  0.5464, -0.4332, -0.9581,\n",
      "          -2.1084],\n",
      "         [ 0.2470,  2.2259, -0.6204, -1.3825, -1.3547, -1.1894, -1.1706,\n",
      "          -1.4953]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[[-0.1519,  1.9822,  2.3017, -2.3442, -3.3201, -2.4310, -3.7513,\n",
      "          -5.7323],\n",
      "         [-0.1519,  1.9822,  2.3017, -2.3442, -3.3201, -2.4310, -3.7513,\n",
      "          -5.7323]]], grad_fn=<SliceBackward0>)\n",
      "tensor([[[ -0.3038,   3.9645,   4.2995,  -0.7240,  -2.0368,  -9.5505, -14.1428,\n",
      "          -16.3266],\n",
      "         [ -0.3038,   3.9645,   4.2995,  -0.7240,  -2.0368,  -9.5505, -14.1428,\n",
      "          -16.3266]]], grad_fn=<SliceBackward0>)\n",
      "tensor([[[ -0.6076,   7.9289,   8.5991,  -1.4480,  -4.6813, -11.1720, -19.6866,\n",
      "          -34.1013],\n",
      "         [ -0.6076,   7.9289,   8.5991,  -1.4480,  -4.6813, -11.1720, -19.6866,\n",
      "          -34.1013]]], grad_fn=<SliceBackward0>)\n",
      "tensor([[[ -1.2153,  15.8578,  17.1982,  -2.8960,  -9.3627, -22.3441, -39.3732,\n",
      "          -68.2026],\n",
      "         [ -1.2153,  15.8578,  17.1982,  -2.8960,  -9.3627, -22.3441, -39.3732,\n",
      "          -68.2026]]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "seq = torch.arange(8, dtype=torch.long).reshape(1, -1)\n",
    "print(seq)\n",
    "\n",
    "embed = nn.Embedding(255, 2)\n",
    "\n",
    "seq = embed(seq)\n",
    "seq = rearrange(seq, \"batch seq channels -> batch channels seq\") # PyTorch Conv1d required order \n",
    "                           \n",
    "print(seq)\n",
    "\n",
    "for dil in (1, 2, 4, 8):\n",
    "    dcc = dccs[dil]\n",
    "    seq = dcc(seq)\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f57eb97-cb5d-472f-adba-372c3ff8d94c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "```\n",
    "our perceptual system feeds raw tokens (photons, waves, etc.) into a Perceiver model that outputs embeddings, which are then processed by other models using a universal set of embeddings\n",
    "\n",
    "the current formulation of \"embeddings\" is holding ML back because it's arbitrary for every new model architecture...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713ede7-5245-48aa-a0b5-892fe1770f5b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## wavenet block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6e9bb83",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "wnb = WaveNetBlock(1, 6, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abeb1712-9bba-4963-81e2-f0af20e55ed2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6415,  2.0079,  1.2987, -1.6521],\n",
      "         [-0.4333,  2.0356,  0.5587, -0.2746],\n",
      "         [ 0.0465, -1.1569, -0.2227, -0.9221],\n",
      "         [-0.3786,  0.3795,  0.8372,  0.6274],\n",
      "         [ 2.1452, -0.3153,  1.5244, -0.4513],\n",
      "         [ 0.5395,  0.7476,  0.0573,  0.9140],\n",
      "         [ 1.0305, -0.6988,  0.3695, -0.6360],\n",
      "         [ 0.1316, -0.8818, -0.1656,  0.4459]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 8, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a00e686e-96d6-4ef7-a971-754bc66ca9b6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2766, -0.2638, -0.0616, -0.0880, -0.0358, -0.1975, -0.0095,\n",
       "           -0.1001],\n",
       "          [ 0.2595,  0.4514,  0.4089,  0.3159,  0.3149,  0.4715,  0.3673,\n",
       "            0.3817],\n",
       "          [-0.3067, -0.1060, -0.3404, -0.4422, -0.4741, -0.0669, -0.4493,\n",
       "           -0.2762],\n",
       "          [-0.4703, -0.5385, -0.4511, -0.4565, -0.4142, -0.4178, -0.4365,\n",
       "           -0.3758]]], grad_fn=<ConvolutionBackward0>),\n",
       " tensor([[[ 0.5628,  0.2582,  0.5419,  0.6263,  0.7145,  0.4346,  0.6398,\n",
       "            0.6511],\n",
       "          [-0.4450, -0.1115, -0.3777, -0.5143, -0.5695, -0.1573, -0.4977,\n",
       "           -0.4053]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnb(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521ef2b5-338f-48a8-b568-228d4de6ad72",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## wavenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff4bbaeb-70e8-4154-89bf-45cd48a8b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = WaveNet(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "370768e9-bdba-482e-820e-2f9666d9a90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 2, 1, 1, 0, 2, 1, 3]])\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.randint(0, 5, (1, 8), dtype=torch.long)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cad1e92-b79e-46a3-823c-bf37e8f10fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9521,  0.9509,  0.4908],\n",
      "         [ 2.2902, -0.5103,  0.3629],\n",
      "         [ 0.8098,  0.8580, -0.1801],\n",
      "         [ 0.8098,  0.8580, -0.1801],\n",
      "         [ 2.4660, -0.2746, -0.0791],\n",
      "         [ 2.2902, -0.5103,  0.3629],\n",
      "         [ 0.8098,  0.8580, -0.1801],\n",
      "         [-0.9521,  0.9509,  0.4908]]], grad_fn=<EmbeddingBackward0>)\n",
      "[tensor([[[0.0453, 0.1430, 0.1095, 0.0920, 0.1358, 0.1542, 0.1095, 0.0638],\n",
      "         [0.1175, 0.4894, 0.3909, 0.3295, 0.5229, 0.5372, 0.3909, 0.1265]]],\n",
      "       grad_fn=<ConvolutionBackward0>), tensor([[[-0.0691, -0.1369,  0.0361, -0.0846, -0.1191, -0.1052, -0.0986,\n",
      "          -0.0434],\n",
      "         [ 0.3147,  0.2504, -0.0290,  0.3456,  0.0863,  0.1387,  0.3233,\n",
      "           0.3268]]], grad_fn=<ConvolutionBackward0>), tensor([[[ 0.0227,  0.3507,  0.1165,  0.1611,  0.3120,  0.3692,  0.1612,\n",
      "           0.1179],\n",
      "         [-0.4224, -0.2954, -0.4045, -0.3934, -0.3220, -0.3053, -0.3876,\n",
      "          -0.3880]]], grad_fn=<ConvolutionBackward0>)]\n",
      "tensor([[[-0.0011,  0.3568,  0.2620,  0.1685,  0.3288,  0.4182,  0.1721,\n",
      "           0.1383],\n",
      "         [ 0.0098,  0.4444, -0.0427,  0.2817,  0.2871,  0.3706,  0.3266,\n",
      "           0.0652]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[-3.0455e-01, -7.0455e-01, -4.2247e-01, -5.2909e-01, -6.0734e-01,\n",
      "          -6.9398e-01, -5.5476e-01, -3.9917e-01],\n",
      "         [ 3.0443e-02, -4.2227e-01, -9.6507e-02, -2.2501e-01, -3.0982e-01,\n",
      "          -4.0736e-01, -2.5486e-01, -7.4411e-02],\n",
      "         [-3.6990e-04,  1.9252e-01,  1.5176e-01,  8.8611e-02,  1.8131e-01,\n",
      "           2.3046e-01,  8.9251e-02,  7.8001e-02],\n",
      "         [ 5.2727e-01,  3.6385e-01,  5.0798e-01,  4.2968e-01,  4.1438e-01,\n",
      "           3.8122e-01,  4.1563e-01,  4.9854e-01]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "tensor([[[ 0.0162, -0.0729, -0.0080, -0.0280, -0.0507, -0.0727, -0.0337,\n",
      "           0.0014],\n",
      "         [-0.2296, -0.1715, -0.1913, -0.1932, -0.1780, -0.1675, -0.1917,\n",
      "          -0.2013],\n",
      "         [ 0.2837,  0.3773,  0.3153,  0.3291,  0.3563,  0.3798,  0.3343,\n",
      "           0.3015],\n",
      "         [ 0.1779,  0.2691,  0.2200,  0.2300,  0.2525,  0.2715,  0.2342,\n",
      "           0.2083],\n",
      "         [ 0.0148,  0.0466,  0.0756,  0.0291,  0.0579,  0.0656,  0.0251,\n",
      "           0.0461]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0162, -0.2296,  0.2837,  0.1779,  0.0148],\n",
       "         [-0.0729, -0.1715,  0.3773,  0.2691,  0.0466],\n",
       "         [-0.0080, -0.1913,  0.3153,  0.2200,  0.0756],\n",
       "         [-0.0280, -0.1932,  0.3291,  0.2300,  0.0291],\n",
       "         [-0.0507, -0.1780,  0.3563,  0.2525,  0.0579],\n",
       "         [-0.0727, -0.1675,  0.3798,  0.2715,  0.0656],\n",
       "         [-0.0337, -0.1917,  0.3343,  0.2342,  0.0251],\n",
       "         [ 0.0014, -0.2013,  0.3015,  0.2083,  0.0461]]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9987f03-d3a6-4f6c-8e38-663d8f935066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavenet",
   "language": "python",
   "name": "wavenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
